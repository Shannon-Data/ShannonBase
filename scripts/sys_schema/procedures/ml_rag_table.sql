-- Copyright (c) 2014, 2023, Oracle and/or its affiliates.
--
-- This program is free software; you can redistribute it and/or modify
-- it under the terms of the GNU General Public License as published by
-- the Free Software Foundation; version 2 of the License.
--
-- This program is distributed in the hope that it will be useful,
-- but WITHOUT ANY WARRANTY; without even the implied warranty of
-- MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-- GNU General Public License for more details.
--
-- You should have received a copy of the GNU General Public License
-- along with this program; if not, write to the Free Software
-- Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
-- Copyright (c) 2023, Shannon Data AI and/or its affiliates.

DROP PROCEDURE IF EXISTS ml_rag_table;

DELIMITER $$

CREATE DEFINER='mysql.sys'@'localhost' PROCEDURE ml_rag_table (
    IN in_input_table_column VARCHAR(255),
    IN in_output_table_column VARCHAR(255),
    IN in_options JSON
)
COMMENT '
Description
-----------
The ML_RAG_TABLE routine runs multiple retrieval-augmented generation (RAG) queries
in a batch, in parallel. The output generated for every input query is the same as
the output generated by the ML_RAG routine.

Parameters
-----------
in_input_table_column (VARCHAR(255)):
  Specifies the names of the input database, table, and column that contains the
  natural-language queries in format: DBName.TableName.ColumnName

in_output_table_column (VARCHAR(255)):
  Specifies the names of the database, table, and column where the generated
  text-based response is stored in format: DBName.TableName.ColumnName

in_options (JSON):
  Specifies optional parameters as key-value pairs:
  - vector_store: JSON array of vector store table names to use
  - schema: JSON array of schema names to search
  - n_citations: number of segments for context retrieval (default: 3, range: 0-100)
  - distance_metric: COSINE|DOT|EUCLIDEAN (default: COSINE)
  - document_name: JSON array of specific documents to use
  - skip_generate: true|false (default: false)
  - model_options: additional options for text generation
  - exclude_vector_store: JSON array of vector stores to exclude
  - exclude_document_name: JSON array of documents to exclude
  - batch_size: batch size for processing (default: 1000, range: 1-1000)
  - retrieval_options: context retrieval parameters
  - vector_store_columns: column name mappings
  - embed_model_id: embedding model to use (default: multilingual-e5-small)
  - embed_column: pre-computed query embeddings column name
  - fail_on_embedding_error: true|false (default: true)

Example
-----------
mysql> CALL sys.ML_RAG_TABLE("demo_db.input_table.Input", "demo_db.output_table.Output",
       JSON_OBJECT("vector_store", JSON_ARRAY("demo_db.demo_embeddings"), "batch_size", 10));
'
SQL SECURITY INVOKER
READS SQL DATA
MODIFIES SQL DATA
BEGIN
    -- =========================
    -- Variable declarations
    -- =========================
    DECLARE v_input_db VARCHAR(64);
    DECLARE v_input_table VARCHAR(64);
    DECLARE v_input_column VARCHAR(64);
    DECLARE v_output_db VARCHAR(64);
    DECLARE v_output_table VARCHAR(64);
    DECLARE v_output_column VARCHAR(64);
    DECLARE v_batch_size INT DEFAULT 1000;
    DECLARE v_fail_on_embedding_error BOOLEAN DEFAULT TRUE;
    DECLARE v_embed_column VARCHAR(64) DEFAULT NULL;

    DECLARE v_current_query_text TEXT;
    DECLARE v_current_rag_output JSON;
    DECLARE v_current_id VARCHAR(255);
    DECLARE v_batch_count INT DEFAULT 0;
    DECLARE v_total_processed INT DEFAULT 0;
    DECLARE v_total_failed INT DEFAULT 0;
    DECLARE v_error_msg TEXT DEFAULT '';

    -- Table existence flags
    DECLARE v_input_table_exists BOOLEAN DEFAULT FALSE;
    DECLARE v_output_table_exists BOOLEAN DEFAULT FALSE;
    DECLARE v_same_table BOOLEAN DEFAULT FALSE;

    -- Cursor variables
    DECLARE done INT DEFAULT FALSE;
    DECLARE batch_cursor CURSOR FOR 
        SELECT pk_values, query_text FROM temp_batch_data ORDER BY batch_order;
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;

    -- Exception handler - FIXED: Use variable for SIGNAL message
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        GET DIAGNOSTICS CONDITION 1 v_error_msg = MESSAGE_TEXT;
        DROP TEMPORARY TABLE IF EXISTS temp_batch_data;
        DROP TEMPORARY TABLE IF EXISTS temp_pk_columns;
        SET v_error_msg = CONCAT('ML_RAG_TABLE failed: ', v_error_msg);
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;
    END;

    -- Input validation
    IF in_input_table_column IS NULL OR TRIM(in_input_table_column) = '' THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Input table column specification cannot be null or empty';
    END IF;

    IF in_output_table_column IS NULL OR TRIM(in_output_table_column) = '' THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Output table column specification cannot be null or empty';
    END IF;

    -- Parse input table specification
    IF (LENGTH(in_input_table_column) - LENGTH(REPLACE(in_input_table_column, '.', ''))) <> 2 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Input table column must be in format: DBName.TableName.ColumnName';
    END IF;
    
    SET v_input_db = SUBSTRING_INDEX(in_input_table_column, '.', 1);
    SET v_input_table = SUBSTRING_INDEX(SUBSTRING_INDEX(in_input_table_column, '.', 2), '.', -1);
    SET v_input_column = SUBSTRING_INDEX(in_input_table_column, '.', -1);

    -- Parse output table specification
    IF (LENGTH(in_output_table_column) - LENGTH(REPLACE(in_output_table_column, '.', ''))) <> 2 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Output table column must be in format: DBName.TableName.ColumnName';
    END IF;

    SET v_output_db = SUBSTRING_INDEX(in_output_table_column, '.', 1);
    SET v_output_table = SUBSTRING_INDEX(SUBSTRING_INDEX(in_output_table_column, '.', 2), '.', -1);
    SET v_output_column = SUBSTRING_INDEX(in_output_table_column, '.', -1);

    -- Parse options
    IF JSON_VALID(in_options) AND in_options IS NOT NULL THEN
        SET v_batch_size = COALESCE(CAST(JSON_UNQUOTE(JSON_EXTRACT(in_options, '$.batch_size')) AS UNSIGNED), 1000);
        SET v_fail_on_embedding_error = COALESCE(CAST(JSON_UNQUOTE(JSON_EXTRACT(in_options, '$.fail_on_embedding_error')) AS UNSIGNED), TRUE);
        SET v_embed_column = JSON_UNQUOTE(JSON_EXTRACT(in_options, '$.embed_column'));
    END IF;

    -- Validate batch_size
    IF v_batch_size < 1 OR v_batch_size > 1000 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'batch_size must be between 1 and 1000';
    END IF;

    -- Check input table existence and structure
    SELECT COUNT(*) > 0 INTO v_input_table_exists
    FROM information_schema.TABLES
    WHERE TABLE_SCHEMA = v_input_db AND TABLE_NAME = v_input_table;

    IF NOT v_input_table_exists THEN
        SET v_error_msg = CONCAT('Input table does not exist: ', v_input_db, '.', v_input_table);
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;
    END IF;

    -- Verify input column exists and is text/varchar
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.COLUMNS 
        WHERE TABLE_SCHEMA = v_input_db 
        AND TABLE_NAME = v_input_table 
        AND COLUMN_NAME = v_input_column
        AND DATA_TYPE IN ('text', 'varchar', 'longtext', 'mediumtext', 'tinytext')
    ) THEN
        SET v_error_msg = CONCAT('Input column does not exist or is not a text type: ', v_input_column);
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;
    END IF;

    -- Verify input table has primary key
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.KEY_COLUMN_USAGE k
        WHERE k.TABLE_SCHEMA = v_input_db 
        AND k.TABLE_NAME = v_input_table
        AND k.CONSTRAINT_NAME = 'PRIMARY'
    ) THEN
        SET v_error_msg = CONCAT('Input table must have a primary key: ', v_input_db, '.', v_input_table);
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;        
    END IF;

    -- Check output table
    SELECT COUNT(*) > 0 INTO v_output_table_exists
    FROM information_schema.TABLES
    WHERE TABLE_SCHEMA = v_output_db AND TABLE_NAME = v_output_table;

    SET v_same_table = (v_input_db = v_output_db AND v_input_table = v_output_table);

    -- If output table exists, must be same as input table
    IF v_output_table_exists AND NOT v_same_table THEN
        SET v_error_msg = 'If output table exists, it must be the same as input table';
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;          
    END IF;

    -- If same table, output column must not exist
    IF v_same_table AND EXISTS (
        SELECT 1 FROM information_schema.COLUMNS 
        WHERE TABLE_SCHEMA = v_output_db 
        AND TABLE_NAME = v_output_table 
        AND COLUMN_NAME = v_output_column
    ) THEN
        SET v_error_msg = CONCAT('Output column already exists: ', v_output_column);
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;            
    END IF;

    -- =========================
    -- Prepare primary key column information
    -- =========================
    DROP TEMPORARY TABLE IF EXISTS temp_pk_columns;
    CREATE TEMPORARY TABLE temp_pk_columns (
        column_name VARCHAR(64),
        column_type TEXT,
        ordinal_position INT,
        PRIMARY KEY (ordinal_position)
    );

    INSERT INTO temp_pk_columns (column_name, column_type, ordinal_position)
    SELECT k.COLUMN_NAME, c.COLUMN_TYPE, k.ORDINAL_POSITION
    FROM information_schema.KEY_COLUMN_USAGE k
    JOIN information_schema.COLUMNS c 
        ON k.TABLE_SCHEMA = c.TABLE_SCHEMA 
        AND k.TABLE_NAME = c.TABLE_NAME 
        AND k.COLUMN_NAME = c.COLUMN_NAME
    WHERE k.TABLE_SCHEMA = v_input_db 
    AND k.TABLE_NAME = v_input_table
    AND k.CONSTRAINT_NAME = 'PRIMARY'
    ORDER BY k.ORDINAL_POSITION;

    -- =========================
    -- Create output table if needed
    -- =========================
    IF NOT v_output_table_exists THEN
        -- Build CREATE TABLE statement with primary key columns
        SET @create_sql = CONCAT('CREATE TABLE `', v_output_db, '`.`', v_output_table, '` (');

        -- Add primary key columns
        SET @pk_columns = '';
        SET @pk_list = '';

        SELECT GROUP_CONCAT(
            CONCAT('`', column_name, '` ', column_type) ORDER BY ordinal_position SEPARATOR ', '
        ), GROUP_CONCAT(
            CONCAT('`', column_name, '`') ORDER BY ordinal_position SEPARATOR ', '
        ) INTO @pk_columns, @pk_list
        FROM temp_pk_columns;

        SET @create_sql = CONCAT(@create_sql, @pk_columns, ', ');
        SET @create_sql = CONCAT(@create_sql, '`', v_output_column, '` JSON, ');
        SET @create_sql = CONCAT(@create_sql, 'PRIMARY KEY (', @pk_list, '))');

        PREPARE create_stmt FROM @create_sql;
        EXECUTE create_stmt;
        DEALLOCATE PREPARE create_stmt;
    ELSE
        -- Add output column to existing table
        SET @alter_sql = CONCAT('ALTER TABLE `', v_output_db, '`.`', v_output_table, 
                               '` ADD COLUMN `', v_output_column, '` JSON');
        PREPARE alter_stmt FROM @alter_sql;
        EXECUTE alter_stmt;
        DEALLOCATE PREPARE alter_stmt;
    END IF;

    -- =========================
    -- Process data in batches
    -- =========================
    SET @batch_offset = 0;

    batch_loop: WHILE TRUE DO
        -- Create temporary table for current batch
        DROP TEMPORARY TABLE IF EXISTS temp_batch_data;
        CREATE TEMPORARY TABLE temp_batch_data (
            batch_order INT AUTO_INCREMENT PRIMARY KEY,
            pk_values JSON,
            query_text LONGTEXT,
            embed_vector VECTOR(384) DEFAULT NULL
        );

        -- Build primary key selection for batch
        SET @pk_select = '';
        SELECT GROUP_CONCAT(
            CONCAT('`', column_name, '`') ORDER BY ordinal_position SEPARATOR ', '
        ) INTO @pk_select
        FROM temp_pk_columns;

        -- Prepare batch query
        SET @batch_sql = CONCAT(
            'INSERT INTO temp_batch_data (pk_values, query_text',
            CASE WHEN v_embed_column IS NOT NULL THEN ', embed_vector' ELSE '' END,
            ') SELECT JSON_ARRAY(', @pk_select, '), `', v_input_column, '`',
            CASE WHEN v_embed_column IS NOT NULL THEN CONCAT(', `', v_embed_column, '`') ELSE '' END,
            ' FROM `', v_input_db, '`.`', v_input_table, '`',
            ' WHERE `', v_input_column, '` IS NOT NULL AND TRIM(`', v_input_column, '`) <> ''''',
            ' LIMIT ', v_batch_size, ' OFFSET ', @batch_offset
        );

        PREPARE batch_stmt FROM @batch_sql;
        EXECUTE batch_stmt;
        DEALLOCATE PREPARE batch_stmt;

        -- Check if batch is empty
        SELECT COUNT(*) INTO v_batch_count FROM temp_batch_data;
        IF v_batch_count = 0 THEN
            LEAVE batch_loop;
        END IF;

        -- Process each row in current batch
        SET done = FALSE;
        OPEN batch_cursor;

        batch_row_loop: LOOP
            FETCH batch_cursor INTO v_current_id, v_current_query_text;
            IF done THEN
                LEAVE batch_row_loop;
            END IF;

            -- Process single RAG query
            BEGIN
                DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
                BEGIN
                    SET v_total_failed = v_total_failed + 1;
                    IF v_fail_on_embedding_error THEN
                        GET DIAGNOSTICS CONDITION 1 v_error_msg = MESSAGE_TEXT;
                        SET v_error_msg = CONCAT('Batch processing failed: ', v_error_msg);
                        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = v_error_msg;
                    ELSE
                        -- Continue processing other rows
                        SET v_current_rag_output = JSON_OBJECT(
                            'error', 'Failed to process this query',
                            'text', '',
                            'citations', JSON_ARRAY()
                        );
                    END IF;
                END;

                -- Add pre-computed embedding to options if available
                SET @rag_options = in_options;
                IF v_embed_column IS NOT NULL THEN
                    SELECT embed_vector INTO @current_embedding 
                    FROM temp_batch_data 
                    WHERE pk_values = v_current_id;

                    IF @current_embedding IS NOT NULL THEN
                        SET @rag_options = JSON_SET(
                            COALESCE(@rag_options, JSON_OBJECT()),
                            '$.query_embedding', 
                            VECTOR_TO_STRING(@current_embedding)
                        );
                    END IF;
                END IF;

                -- Call ML_RAG for single query
                CALL sys.ML_RAG(v_current_query_text, v_current_rag_output, @rag_options);

                SET v_total_processed = v_total_processed + 1;

            END;

            -- Update output table with result
            SET @pk_conditions = '';
            SET @pk_count = (SELECT COUNT(*) FROM temp_pk_columns);
            SET @i = 0;

            WHILE @i < @pk_count DO
                SELECT column_name INTO @col_name 
                FROM temp_pk_columns 
                WHERE ordinal_position = @i + 1;

                SET @pk_conditions = CONCAT(
                    @pk_conditions,
                    IF(@i > 0, ' AND ', ''),
                    '`', @col_name, '` = JSON_UNQUOTE(JSON_EXTRACT(''', 
                    REPLACE(v_current_id, '''', ''''''), 
                    ''', ''$[', @i, ']''))'
                );
                SET @i = @i + 1;
            END WHILE;

            SET @update_sql = CONCAT(
                'UPDATE `', v_output_db, '`.`', v_output_table, '` ',
                'SET `', v_output_column, '` = ''', 
                REPLACE(JSON_UNQUOTE(v_current_rag_output), '''', ''''''), 
                ''' WHERE ', @pk_conditions
            );

            PREPARE update_stmt FROM @update_sql;
            EXECUTE update_stmt;
            DEALLOCATE PREPARE update_stmt;

        END LOOP;

        CLOSE batch_cursor;

        -- Move to next batch
        SET @batch_offset = @batch_offset + v_batch_size;

    END WHILE batch_loop;

    -- Clean up
    DROP TEMPORARY TABLE IF EXISTS temp_batch_data;
    DROP TEMPORARY TABLE IF EXISTS temp_pk_columns;

    -- Return processing summary
    SELECT CONCAT(
        'ML_RAG_TABLE processing completed. ',
        'Total processed: ', v_total_processed, ', ',
        'Total failed: ', v_total_failed
    ) AS processing_summary;

END$$

DELIMITER ;